{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the original MobileNetV2 with RGB color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, json, argparse, torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from utils import image\n",
    "from utils.MobileNetV2_pretrained_imagenet import MobileNetV2\n",
    "from utils.data import NumpyImageLoader\n",
    "from utils.metrics import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print parameters\n",
    "\n",
    "params = {}\n",
    "params[\"channel\"] = \"RGB\"\n",
    "params[\"threshold\"] = 0.500\n",
    "params[\"test_subset\"] = 5\n",
    "\n",
    "params[\"patch_test_au_dir\"] = \"backup/MBN2-RGB/test/au\"\n",
    "params[\"patch_test_tp_dir\"] = \"backup/MBN2-RGB/test/tp\"\n",
    "\n",
    "params[\"training_log_dir\"] = \"backup/MBN2-RGB/checkpoints/\"\n",
    "MODEL_FILE = os.path.join(params[\"training_log_dir\"], \"model.ckpt\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "params[\"au_subsets_file\"] = \"dataset/au_subsets.json\"\n",
    "params[\"tp_subsets_file\"] = \"dataset/tp_subsets.json\"\n",
    "\n",
    "params[\"casia2_au\"] = \"/media/antiaegis/storing/datasets/CASIA2/Au\"\n",
    "params[\"casia2_tp\"] = \"/media/antiaegis/storing/datasets/CASIA2/Tp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directories(list_dirs):\n",
    "    for dir in list_dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            print(\"makedirs\", dir)\n",
    "            os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check directories\n",
    "\n",
    "list_dirs = [\n",
    "    params[\"patch_test_au_dir\"],\n",
    "    params[\"patch_test_tp_dir\"],\n",
    "]\n",
    "check_directories(list_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "model = MobileNetV2(n_class=2, input_size=64, width_mult=1.0).to(device=DEVICE)\n",
    "model.load(model_file=MODEL_FILE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files\n",
    "\n",
    "with open(params[\"au_subsets_file\"], \"r\") as fp:\n",
    "    au_subsets = json.load(fp)\n",
    "fnames_au = au_subsets[str(params[\"test_subset\"])]\n",
    "N_au = len(fnames_au)\n",
    "\n",
    "with open(params[\"tp_subsets_file\"], \"r\") as fp:\n",
    "    tp_subsets = json.load(fp)\n",
    "fnames_tp = tp_subsets[str(params[\"test_subset\"])]\n",
    "N_tp = len(fnames_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict authentic patches\n",
    "\n",
    "scores_au = []\n",
    "for i in tqdm(range(N_au), total=N_au):\n",
    "    # Crop patches in the image\n",
    "    fname = fnames_au[i]\n",
    "    file = os.path.join(params[\"casia2_au\"], fname)\n",
    "    img = image.read(file, params[\"channel\"])\n",
    "\n",
    "    coords, _, _ = image.slide2d(sz=img.shape[:2], K=64, S=32)\n",
    "    patches = image.crop_patches(img=img, coords=coords, patch_sz=64)\n",
    "\n",
    "    # Create dataloader of the cropped patches\n",
    "    loader = NumpyImageLoader(\n",
    "        ndarray_data=patches,\n",
    "        batch_size=16,\n",
    "        n_workers=cpu_count(),\n",
    "        pin_memory=True,\n",
    "        shuffle=False\n",
    "    ).loader\n",
    "\n",
    "    # Predict labels\n",
    "    softmaxs = []\n",
    "    for X in loader:\n",
    "        X = X[0].to(DEVICE)\n",
    "        logits = model(X)\n",
    "        softmaxs.append(F.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "    softmaxs = np.concatenate(softmaxs, axis=0)\n",
    "\n",
    "    # Save result into disk\n",
    "    np.save(\n",
    "        os.path.join(params[\"patch_test_au_dir\"], fname),\n",
    "        {\"softmaxs\": softmaxs, \"coords\": coords}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict tampered images\n",
    "\n",
    "scores_tp = []\n",
    "for i in tqdm(range(N_tp), total=N_tp):\n",
    "    # Crop patches in the image\n",
    "    fname = fnames_tp[i]\n",
    "    file = os.path.join(params[\"casia2_tp\"], fname)\n",
    "    img = image.read(file, params[\"channel\"])\n",
    "\n",
    "    coords, _, _ = image.slide2d(sz=img.shape[:2], K=64, S=32)\n",
    "    patches = image.crop_patches(img=img, coords=coords, patch_sz=64)\n",
    "\n",
    "    # Create dataloader of the cropped patches\n",
    "    loader = NumpyImageLoader(\n",
    "        ndarray_data=patches,\n",
    "        batch_size=16,\n",
    "        n_workers=cpu_count(),\n",
    "        pin_memory=True,\n",
    "        shuffle=False\n",
    "    ).loader\n",
    "\n",
    "    # Predict labels\n",
    "    softmaxs = []\n",
    "    for X in loader:\n",
    "        X = X[0].to(DEVICE)\n",
    "        logits = model(X)\n",
    "        softmaxs.append(F.softmax(logits, dim=1).detach().cpu().numpy())\n",
    "    softmaxs = np.concatenate(softmaxs, axis=0)\n",
    "\n",
    "    # Save result into disk\n",
    "    np.save(\n",
    "        os.path.join(params[\"patch_test_tp_dir\"], fname),\n",
    "        {\"softmaxs\": softmaxs, \"coords\": coords}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on predicted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parallel pools\n",
    "\n",
    "pools = Pool(processes=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about files on disk\n",
    "\n",
    "au_files = glob(os.path.join(params[\"patch_test_au_dir\"], \"*.*\"))\n",
    "tp_files = glob(os.path.join(params[\"patch_test_tp_dir\"], \"*.*\"))\n",
    "n_au_files, n_tp_files = len(au_files), len(tp_files)\n",
    "scores_au, scores_tp = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1253/1253 [00:05<00:00, 249.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test on authentic images\n",
    "\n",
    "for i, file in tqdm(enumerate(au_files), total=n_au_files):\n",
    "    # Load softmaxs and coords from disk\n",
    "    data = np.load(file).item()\n",
    "    softmaxs, coords = data[\"softmaxs\"], data[\"coords\"]\n",
    "    softmaxs = softmaxs[:, 1]\n",
    "\n",
    "    # Postprocess\n",
    "    labels = image.post_process(softmaxs, coords, 8, params[\"threshold\"], 32, pools=pools)\n",
    "    mark = image.fusion(labels)\n",
    "    scores_au.append(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [00:04<00:00, 189.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test on tampered images\n",
    "\n",
    "for i, file in tqdm(enumerate(tp_files), total=n_tp_files):\n",
    "    # Load softmaxs and coords from disk\n",
    "    data = np.load(file).item()\n",
    "    softmaxs, coords = data[\"softmaxs\"], data[\"coords\"]\n",
    "    softmaxs = softmaxs[:, 1]\n",
    "\n",
    "    # Postprocess\n",
    "    labels = image.post_process(softmaxs, coords, 8, params[\"threshold\"], 32, pools=pools)\n",
    "    mark = image.fusion(labels)\n",
    "    scores_tp.append(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 88.51 %; FP = 11.49 %\n",
      "TN = 72.39 %; FN = 27.61 %\n",
      "Accuracy = 78.50 %\n",
      "Precision = 88.51 %\n",
      "Recall = 66.21 %\n",
      "F-score = 75.75 %\n"
     ]
    }
   ],
   "source": [
    "# Print testing metrics\n",
    "\n",
    "metrics = BinaryClassificationMetrics()\n",
    "metrics.compute_all(scores_tp, scores_au)\n",
    "metrics.print_metrics()\n",
    "# metrics.write_to_file(params[\"test_result_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close parallel pools\n",
    "\n",
    "pools.close()\n",
    "pools.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
